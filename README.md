# ğŸš€ Epopee LinkedIn â€“ CrewAI

Epopee LinkedIn automatise la collecte et l'analyse d'informations autour d'un prospect afin de prÃ©parer une stratÃ©gie de prise de contact multicanale. Le projet s'appuie sur [CrewAI](https://crewai.com) et une sÃ©rie d'agents spÃ©cialisÃ©s (LinkedIn, scraping web, veille sectorielle, stratÃ©gie commerciale).

## ğŸ§° PrÃ©requis

- PythonÂ â‰¥Â 3.10 et <Â 3.14
- [uv](https://docs.astral.sh/uv/) pour la gestion des dÃ©pendances Python
- Node.jsÂ â‰¥Â 18 (utilisÃ© pour lancer les serveurs MCP via `npx`)
- AccÃ¨s aux API nÃ©cessairesÂ :
  - `OPENAI_API_KEY` (modÃ¨le principal de gÃ©nÃ©ration)
  - `SERPER_API_KEY` (recherche web)
  - `HDW_ACCESS_TOKEN` & `HDW_ACCOUNT_ID` (serveur Horizon Data Wave pour LinkedIn)
  - Autres clÃ©s optionnelles selon vos outils (`XAI_API_KEY`, LM Studio, etc.)

## âš™ï¸ Installation

1. Cloner le dÃ©pÃ´t puis se placer Ã  la racine du projet (`epolin`).
2. Installer les dÃ©pendances PythonÂ :

   ```bash
   uv sync
   ```

   Le fichier `pyproject.toml` dÃ©clare toutes les dÃ©pendances ; aucun `requirements.txt` supplÃ©mentaire n'est nÃ©cessaire.

3. (Optionnel) Si vous prÃ©fÃ©rez `crewai install`, la commande reste compatible.

## ğŸ” Configuration des secrets

1. Dupliquer le fichier `.env.example` â†’ `.env`.
2. Renseigner les valeurs des clÃ©s :

   ```env
   OPENAI_API_KEY=...
   SERPER_API_KEY=...
   XAI_API_KEY=...
   CREWAI_TRACING_ENABLED=true
   HDW_ACCESS_TOKEN=...
   HDW_ACCOUNT_ID=...
   LM_STUDIO_API_BASE=...
   LM_STUDIO_API_KEY=...
   ```

   > Ne versionnez jamais votre `.env` rempli.

## ğŸ§  DonnÃ©es d'entrÃ©e & personnalisation

- Les paramÃ¨tres par dÃ©faut sont dÃ©finis dans `src/epolin/main.py` via `DEFAULT_INPUTS` (`prospect`, `website_url`). Adaptez-les ou chargez vos propres valeurs depuis la CLI/`.env` si besoin.
- Les agents sont dÃ©crits dans `src/epolin/config/agents.yaml` et les tÃ¢ches dans `src/epolin/config/tasks.yaml`. Chaque tÃ¢che rÃ©fÃ©rence un agent et gÃ©nÃ¨re un livrable (`01_PROFIL_LINKEDIN.md`, etc.).
- Les fichiers de connaissance situÃ©s dans `knowledge/` peuvent Ãªtre enrichis pour fournir du contexte supplÃ©mentaire (ex. `info_laurent.md`).

### Agents principaux

- `profil_social_agent`Â : recherche et enrichissement LinkedIn via MCP Horizon Data Wave.
- `web_company_agent`Â : scraping du site officiel + fiche MCP recherche-entreprises.
- `sector_watch_agent`Â : veille sectorielle assistÃ©e par Serper.
- `outreach_strategy_agent`Â : synthÃ¨se finale et stratÃ©gie de contact.

## â–¶ï¸ Lancer la crew

Depuis la racine du projet :

```bash
uv run run_crew
```

ou avec l'alias CrewAI :

```bash
crewai run
```

Les livrables sont gÃ©nÃ©rÃ©s Ã  la racine (`01_PROFIL_LINKEDIN.md`, `02_POSTS_LINKEDIN.md`, etc.).

### Autres commandes utiles

- `uv run train <n> <fichier>.jsonl` : replays automatiques.
- `uv run replay <task_id>` : relancer une exÃ©cution.
- `uv run test <n> <eval_llm>` : boucle d'Ã©valuation automatique.

## ğŸ› ï¸ Outils MCP

Le projet utilise deux serveurs MCP dÃ©marrÃ©s via `npx` :

- `@horizondatawave/mcp` (LinkedIn)
- `mcp-recherche-entreprises` (donnÃ©es INSEE)

Assurez-vous que `npx` est disponible et que vos tokens HDW sont valides. Ajustez le timeout ou les paramÃ¨tres dans `src/epolin/crew.py` si nÃ©cessaire.

## ğŸ§ª Tests & validation

- AprÃ¨s modification, exÃ©cuter `uv run run_crew` pour valider le pipeline.
- Les tests automatisÃ©s (rÃ©pertoires `tests/`) peuvent Ãªtre adaptÃ©s pour vÃ©rifier des modules spÃ©cifiques.

## ğŸ¤ Contribution

1. Fork / branche dÃ©diÃ©e
2. `uv sync`
3. ImplÃ©mentation + gÃ©nÃ©ration des livrables
4. `uv run run_crew` pour valider
5. Commit + PR

## ğŸ“š Ressources complÃ©mentaires

- [Documentation CrewAI](https://docs.crewai.com)
- [Documentation MCP](https://modelcontextprotocol.io)
- Support interne : voir les fichiers `knowledge/`

Bon buildÂ ! ğŸš€
